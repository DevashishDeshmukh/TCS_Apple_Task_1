# TCS_Apple_Training_Task_1
 
## Model used : TinyLlama
### This model is running locally using ollama.
Part 1: Build a FastAPI application to query general knowledge question to LLM. LLLM must be running locally. 

Part 2: Log an each API calls with unique identifier in console log along with user query and LLM response. This identifier should be backtracked at API Level.



### Steps to run on local system
1. Clone the repo.
2. Download and install ollama on the local system.
3. Set up TinyLlama using ollama - (ollama pull tinyllama)
4. Then run TinyLlama using (ollama run tinyllama)
5. Then run code using (uvicorn main:app --reload)
6. Open the link in browser

### Steps to use
1. enter prompt
2. click the submit button
